{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your first task is to create a stacked chart of **unique online devices per\n",
    "day**, segregated by fleet size. The fleet size is an attribute of each user\n",
    "and is defined as the number of online devices that this user had at a\n",
    "particular day. You can split the dataset in the following fleet sizes:\n",
    "\n",
    "* 1-2 devices\n",
    "* 3-9 devices\n",
    "* 10-99 devices\n",
    "* 100-999 devices\n",
    "\n",
    "A device should be counted as online for a particular day if it was online for\n",
    "any amount of time during that day. For example, a device that appear online\n",
    "for only a second should still be counted for that day.\n",
    "\n",
    "The specific rules we have selected to deal with problematic sections\n",
    "of a device's timeline can be summarised in the following table:\n",
    "\n",
    "| current event | current server | next event | next server | rule        |\n",
    "|---------------|----------------|------------|-------------|-------------|\n",
    "| online        | X              | online     | X           | Assume device was online from current event's timestamp until next event's timestamp\n",
    "| online        | X              | online     | Y           | Assume device was online from current event's timestamp until X's destruction time or next event's timestamp, whichever is smaller\n",
    "| online        | X              | offline    | X           | Normal case\n",
    "| online        | X              | offline    | Y           | Assume device was online from current event's timestamp until X's destruction time. Ignore next event.\n",
    "| offline       | X              | online     | X           | Normal case\n",
    "| offline       | X              | online     | Y           | Normal case\n",
    "| offline       | X              | offline    | X           | Ignore next event\n",
    "| offline       | X              | offline    | Y           | Ignore next event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prev_server(df):\n",
    "    \"\"\"\n",
    "    calculate previous server connection's data: previous server id, previous connected status and previous timestamp\n",
    "    \"\"\"\n",
    "    df['prev_server_id']=(df.sort_values(['timestamp'], ascending=True)\n",
    "                               .groupby(['device_id'])['server_id'].shift(-1))\n",
    "    df['prev_connected']=(df.sort_values(['timestamp'], ascending=True)\n",
    "                             .groupby(['device_id'])['connected'].shift(-1)).astype(bool)\n",
    "    df['prev_timestamp']=(df.sort_values(['timestamp'], ascending=True)\n",
    "                                             .groupby(['device_id'])['timestamp'].shift(-1))\n",
    "    df['ignored']=False\n",
    "\n",
    "def mark_ignored_rows(row):\n",
    "    \"\"\"\n",
    "    function to mark rows as ignored, cases:\n",
    "    1. X offline -> X offline\n",
    "    2. X offline -> Y offline\n",
    "    \"\"\"\n",
    "    return row['connected']==False and row['prev_connected']==False\n",
    "\n",
    "    \n",
    "def process_dataframe(df):\n",
    "    df['ignored'] = df.apply(lambda row: prepare_final(row), axis=1)\n",
    "\n",
    "def parallelize_dataframe(df, func, n_cores=4):\n",
    "    pool = Pool(n_cores)\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['id','created_at','destroyed_at']\n",
    "servers = pd.read_csv('data/servers.csv',names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['timestamp','device_id', 'user_id','server_id','connected']\n",
    "events = pd.read_csv('data/connectivity_events.csv',names=names)#,nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9308207"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_merged=events.merge(servers,left_on='server_id',right_on='id')\n",
    "events_merged.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.1 s ± 1.89 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "prev_server(events_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>device_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>server_id</th>\n",
       "      <th>connected</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>destroyed_at</th>\n",
       "      <th>prev_server_id</th>\n",
       "      <th>prev_connected</th>\n",
       "      <th>prev_timestamp</th>\n",
       "      <th>ignored</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-31 14:30:00</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-31 14:30:00.000000</td>\n",
       "      <td>2017-08-03 22:42:57.929</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-06-02 10:30:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-31 14:30:00</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-31 14:30:00.000000</td>\n",
       "      <td>2017-08-03 22:42:57.929</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-05-31 18:30:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-31 14:30:00</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-31 14:30:00.000000</td>\n",
       "      <td>2017-08-03 22:42:57.929</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-05-31 19:30:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2015-05-31 14:30:00</td>\n",
       "      <td>103</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-31 14:30:00.000000</td>\n",
       "      <td>2017-08-03 22:42:57.929</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-06-01 02:30:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2015-05-31 14:30:00</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-31 14:30:00.000000</td>\n",
       "      <td>2017-08-03 22:42:57.929</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-06-06 02:30:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  device_id  user_id  server_id  connected  id  \\\n",
       "0  2015-05-31 14:30:00        100        4          2       True   2   \n",
       "1  2015-05-31 14:30:00        101        1          2       True   2   \n",
       "2  2015-05-31 14:30:00        102        1          2       True   2   \n",
       "3  2015-05-31 14:30:00        103       26          2       True   2   \n",
       "4  2015-05-31 14:30:00        104        1          2       True   2   \n",
       "\n",
       "                   created_at             destroyed_at  prev_server_id  \\\n",
       "0  2015-05-31 14:30:00.000000  2017-08-03 22:42:57.929             2.0   \n",
       "1  2015-05-31 14:30:00.000000  2017-08-03 22:42:57.929             2.0   \n",
       "2  2015-05-31 14:30:00.000000  2017-08-03 22:42:57.929             2.0   \n",
       "3  2015-05-31 14:30:00.000000  2017-08-03 22:42:57.929             2.0   \n",
       "4  2015-05-31 14:30:00.000000  2017-08-03 22:42:57.929             2.0   \n",
       "\n",
       "   prev_connected       prev_timestamp  ignored  \n",
       "0           False  2015-06-02 10:30:00    False  \n",
       "1           False  2015-05-31 18:30:00    False  \n",
       "2           False  2015-05-31 19:30:00    False  \n",
       "3           False  2015-06-01 02:30:00    False  \n",
       "4           False  2015-06-06 02:30:00    False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sort_values() got an unexpected keyword argument 'by'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/jakkie/opt/anaconda3/envs/PythonR/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/jakkie/opt/anaconda3/envs/PythonR/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"/Users/jakkie/opt/anaconda3/envs/PythonR/lib/python3.7/site-packages/pandarallel/pandarallel.py\", line 59, in global_worker\n    return _func(x)\n  File \"/Users/jakkie/opt/anaconda3/envs/PythonR/lib/python3.7/site-packages/pandarallel/pandarallel.py\", line 143, in wrapper\n    **kwargs\n  File \"/Users/jakkie/opt/anaconda3/envs/PythonR/lib/python3.7/site-packages/pandarallel/data_types/dataframe.py\", line 31, in worker\n    return df.apply(func, *args, **kwargs)\n  File \"/Users/jakkie/opt/anaconda3/envs/PythonR/lib/python3.7/site-packages/pandas/core/frame.py\", line 6878, in apply\n    return op.get_result()\n  File \"/Users/jakkie/opt/anaconda3/envs/PythonR/lib/python3.7/site-packages/pandas/core/apply.py\", line 186, in get_result\n    return self.apply_standard()\n  File \"/Users/jakkie/opt/anaconda3/envs/PythonR/lib/python3.7/site-packages/pandas/core/apply.py\", line 296, in apply_standard\n    values, self.f, axis=self.axis, dummy=dummy, labels=labels\n  File \"pandas/_libs/reduction.pyx\", line 620, in pandas._libs.reduction.compute_reduction\n  File \"pandas/_libs/reduction.pyx\", line 128, in pandas._libs.reduction.Reducer.get_result\n  File \"<ipython-input-20-64ba1f483d7a>\", line 2, in generate_previous_connection\n    df['prev_server_id']=(df.sort_values(by=['timestamp'], ascending=True)\nTypeError: sort_values() got an unexpected keyword argument 'by'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b7612bcfb0a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pandarallel.initialize()\\nevents_merged.parallel_apply(generate_previous_connection)\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonR/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2360\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonR/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonR/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonR/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonR/lib/python3.7/site-packages/pandarallel/pandarallel.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m(data, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m                 \u001b[0minput_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                 \u001b[0moutput_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m                 \u001b[0mmap_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             )\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonR/lib/python3.7/site-packages/pandarallel/pandarallel.py\u001b[0m in \u001b[0;36mget_workers_result\u001b[0;34m(use_memory_fs, nb_workers, show_progress_bar, nb_columns, queue, chunk_lengths, input_files, output_files, map_result)\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0mprogress_bars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogresses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     return (\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonR/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sort_values() got an unexpected keyword argument 'by'"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pandarallel.initialize()\n",
    "events_merged.parallel_apply(generate_previous_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9251905"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_merged[events_merged['prev_timestamp'].notna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>device_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>server_id</th>\n",
       "      <th>connected</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>destroyed_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3684102</th>\n",
       "      <td>2017-11-02 19:38:59.192</td>\n",
       "      <td>9529</td>\n",
       "      <td>168</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>2017-10-17 00:50:09.487556</td>\n",
       "      <td>2017-11-03 20:15:19.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4729335</th>\n",
       "      <td>2017-11-26 22:13:32.274</td>\n",
       "      <td>40702</td>\n",
       "      <td>2359</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>2017-11-22 16:15:57.285482</td>\n",
       "      <td>2017-12-08 23:35:12.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401275</th>\n",
       "      <td>2017-10-04 15:22:18.894</td>\n",
       "      <td>9529</td>\n",
       "      <td>168</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>2017-09-26 16:10:36.230545</td>\n",
       "      <td>2017-10-10 20:31:43.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7586288</th>\n",
       "      <td>2018-01-15 10:55:43.185</td>\n",
       "      <td>20685</td>\n",
       "      <td>1325</td>\n",
       "      <td>29</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "      <td>2018-01-12 17:01:54.553283</td>\n",
       "      <td>2018-02-12 15:06:52.974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9205922</th>\n",
       "      <td>2018-02-26 17:17:01.703</td>\n",
       "      <td>32193</td>\n",
       "      <td>3455</td>\n",
       "      <td>33</td>\n",
       "      <td>False</td>\n",
       "      <td>33</td>\n",
       "      <td>2018-02-26 15:52:13.678326</td>\n",
       "      <td>2018-03-01 18:05:54.051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       timestamp  device_id  user_id  server_id  connected  \\\n",
       "3684102  2017-11-02 19:38:59.192       9529      168         16      False   \n",
       "4729335  2017-11-26 22:13:32.274      40702     2359         20      False   \n",
       "2401275  2017-10-04 15:22:18.894       9529      168         13      False   \n",
       "7586288  2018-01-15 10:55:43.185      20685     1325         29       True   \n",
       "9205922  2018-02-26 17:17:01.703      32193     3455         33      False   \n",
       "\n",
       "         id                  created_at             destroyed_at  \n",
       "3684102  16  2017-10-17 00:50:09.487556  2017-11-03 20:15:19.644  \n",
       "4729335  20  2017-11-22 16:15:57.285482  2017-12-08 23:35:12.164  \n",
       "2401275  13  2017-09-26 16:10:36.230545  2017-10-10 20:31:43.062  \n",
       "7586288  29  2018-01-12 17:01:54.553283  2018-02-12 15:06:52.974  \n",
       "9205922  33  2018-02-26 15:52:13.678326  2018-03-01 18:05:54.051  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = events_merged.sample(100000)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp          object\n",
       "device_id           int64\n",
       "user_id             int64\n",
       "server_id           int64\n",
       "connected            bool\n",
       "id                  int64\n",
       "created_at         object\n",
       "destroyed_at       object\n",
       "prev_server_id    float64\n",
       "prev_connected       bool\n",
       "prev_timestamp     object\n",
       "ignored              bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    10000\n",
       "Name: ignored, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['ignored'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test['ignored'] = test.apply (lambda row: prepare_final(row), axis=1)\n",
    "process_dataframe(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    9621\n",
       "True      379\n",
       "Name: ignored, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['ignored'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4092"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[(test['connected']==False) & (test['prev_connected']==False)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2min 7s ± 3.16 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "process_dataframe(events_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "42.2 s ± 1.4 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pandarallel.initialize()\n",
    "events_merged['ignored'] = events_merged.parallel_apply(lambda row: prepare_final(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379931\n",
      "379931\n"
     ]
    }
   ],
   "source": [
    "print(events_merged[(events_merged['connected']==False) & (events_merged['prev_connected']==False)].shape[0])\n",
    "print(events_merged[events_merged['ignored']==True].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"end:{}\".format(datetime.datetime.now()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
